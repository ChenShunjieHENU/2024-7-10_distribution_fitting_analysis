{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cb574a-c9f7-4e40-80fb-0005fe0089b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylab\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy import stats\n",
    "from scipy.stats import ks_2samp\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "def dir_path(sPath):\n",
    "    total_path = []\n",
    "\n",
    "    def print_dir_contents(sPath):\n",
    "        nonlocal total_path\n",
    "\n",
    "        for schild in os.listdir(sPath):\n",
    "            sChildPath = os.path.join(sPath, schild)\n",
    "            if os.path.isdir(sChildPath):\n",
    "                print_dir_contents(sChildPath)\n",
    "            elif schild.endswith('.csv'):\n",
    "                total_path.append(sChildPath)\n",
    "\n",
    "        return total_path\n",
    "\n",
    "    total_path = print_dir_contents(sPath)\n",
    "    return total_path\n",
    "\n",
    "def em_dweibull(data, max_iter=100, tol=1e-4):\n",
    "    def log_likelihood(params, data):\n",
    "        c, loc, scale = params\n",
    "        return -np.sum(stats.dweibull.logpdf(data, c, loc, scale))\n",
    "    c_init = 1.0\n",
    "    loc_init = np.mean(data)\n",
    "    scale_init = np.std(data)\n",
    "    params_init = np.array([c_init, loc_init, scale_init])\n",
    "    \n",
    "    result = minimize(log_likelihood, params_init, args=(data,), method='L-BFGS-B',\n",
    "                      bounds=[(0.1, None), (None, None), (0.1, None)])\n",
    "\n",
    "    c, loc, scale = result.x\n",
    "    return c, loc, scale\n",
    "\n",
    "def gaussian_mixture_distribution(csv_path):\n",
    "    mydata = pd.read_csv(csv_path)\n",
    "    mydata = mydata.T\n",
    "    mydata.columns = mydata.iloc[0]\n",
    "    mydata = mydata.drop(mydata.index[0])\n",
    "    mydata = mydata.astype('float64')\n",
    "\n",
    "    all_dists_df = pd.DataFrame(columns=['gene', 'Distribution', 'param', 'sumsquare_error', 'aic', 'bic', 'ks', 'ks_pvalue'])\n",
    "    for gene in list(mydata.columns):\n",
    "        data = mydata[gene]\n",
    "        if (data==0).all() == False:\n",
    "            data_2d = data.values.reshape(-1, 1)\n",
    "\n",
    "            dis_num = np.array([5])  \n",
    "            results = []\n",
    "            for n in dis_num:\n",
    "                gmm = GaussianMixture(n_components=n, covariance_type='full', max_iter=100, tol=1e-4)\n",
    "                gmm.fit(data_2d)\n",
    "                param = gmm.get_params()\n",
    "                sse = pylab.sum((gmm.predict_proba(data_2d) - data_2d) ** 2)\n",
    "                aic = gmm.aic(data_2d)\n",
    "                bic = gmm.bic(data_2d)\n",
    "                ks_statistic, p_value = ks_2samp(data_2d[:, 0], gmm.sample(len(data_2d))[0][:, 0])\n",
    "                results.append((gene, n, param, sse, aic, bic, ks_statistic, p_value))\n",
    "\n",
    "            df_results = pd.DataFrame(results, columns=['gene', 'Distribution', 'param', 'sumsquare_error', 'aic', 'bic', 'ks', 'ks_pvalue']).sort_values('bic')\n",
    "            all_dists_df = pd.concat([all_dists_df, df_results], axis=0)\n",
    "\n",
    "    all_dists_df = all_dists_df.reset_index(drop=True)\n",
    "    return all_dists_df\n",
    "\n",
    "def set_distribution(csv_path):\n",
    "    mydata = pd.read_csv(csv_path)\n",
    "    mydata = mydata.T\n",
    "    mydata.columns = mydata.iloc[0]\n",
    "    mydata = mydata.drop(mydata.index[0])\n",
    "    mydata = mydata.astype('float64')\n",
    "\n",
    "    all_dists_df = pd.DataFrame(columns=['gene', 'Distribution', 'param', 'sumsquare_error', 'aic', 'bic', 'ks', 'ks_pvalue'])\n",
    "    for gene in list(mydata.columns):\n",
    "        data = mydata[gene]\n",
    "        if (data==0).all() == False:\n",
    "            results = []\n",
    "            dist_names = ['norm', 't', 'pareto', 'genextreme', 'laplace', 'cauchy', 'chi2', 'expon', 'exponpow', 'gamma', 'beta', 'lognorm', 'loggamma', 'uniform']\n",
    "            for dist_name in dist_names:\n",
    "                dist = getattr(stats, dist_name)\n",
    "                param = dist.fit(data)\n",
    "                log_likelihood = np.sum(dist.logpdf(data, *param))\n",
    "                pdf_fitted = dist.pdf(data, *param[:-2], loc=param[-2], scale=param[-1])\n",
    "                sse = np.sum(np.power(pdf_fitted - data, 2.0))\n",
    "                n = len(data)\n",
    "                k = len(param)\n",
    "                aic = -2 * log_likelihood + 2 * k\n",
    "                bic = -2 * log_likelihood + k * np.log(len(data))\n",
    "                ks_test, p_value = stats.kstest(data, dist_name, args=param)\n",
    "                results.append((gene, dist_name, param, sse, aic, bic, ks_test, p_value))\n",
    "\n",
    "            # EM for dweibull\n",
    "            dweibull_param = em_dweibull(data)\n",
    "            log_likelihood = np.sum(stats.dweibull.logpdf(data, *dweibull_param))\n",
    "            pdf_fitted = stats.dweibull.pdf(data, *dweibull_param)\n",
    "            sse = np.sum(np.power(pdf_fitted - data, 2.0))\n",
    "            n = len(data)\n",
    "            k = len(dweibull_param)\n",
    "            aic = -2 * log_likelihood + 2 * k\n",
    "            bic = -2 * log_likelihood + k * np.log(len(data))\n",
    "            ks_test, p_value = stats.kstest(data, 'dweibull', args=dweibull_param)\n",
    "            results.append((gene, 'dweibull_em', dweibull_param, sse, aic, bic, ks_test, p_value))\n",
    "\n",
    "            df_results = pd.DataFrame(results, columns=['gene', 'Distribution', 'param', 'sumsquare_error', 'aic', 'bic', 'ks', 'ks_pvalue']).sort_values('bic')\n",
    "            all_dists_df = pd.concat([all_dists_df, df_results], axis=0)\n",
    "\n",
    "    all_dists_df = all_dists_df.reset_index(drop=True)\n",
    "    return all_dists_df\n",
    "\n",
    "def identify_sample(num_greater_than_2nd_col, num_greater_than_1st_col):\n",
    "    if num_greater_than_2nd_col > num_greater_than_1st_col:\n",
    "        return 'cancer'\n",
    "    else:\n",
    "        return 'normal'\n",
    "    \n",
    "\n",
    "def laplace_smoothing(x):\n",
    "    return (x + 1) / (x.sum() + len(x))    \n",
    "    \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_data(data_path):\n",
    "    data = pd.read_csv(data_path, index_col=0)\n",
    "    cancer_samples = data.columns[:126]\n",
    "    normal_samples = data.columns[126:]\n",
    "    test_size_temp= 0.2\n",
    "    labels = pd.DataFrame({'label': [1] * len(cancer_samples) + [0] * len(normal_samples)},\n",
    "                          index=cancer_samples.tolist() + normal_samples.tolist())\n",
    "    cancer_train, cancer_test = train_test_split(cancer_samples, test_size=test_size_temp)\n",
    "    normal_train, normal_test = train_test_split(normal_samples, test_size=test_size_temp)\n",
    "    train_samples = list(cancer_train) + list(normal_train)\n",
    "    test_samples = list(cancer_test) + list(normal_test)\n",
    "    train_data = data.loc[:, train_samples]\n",
    "    test_data = data.loc[:, test_samples]\n",
    "    test_labels = labels.loc[test_samples]\n",
    "    cancer_train_data = data.loc[:, cancer_train]\n",
    "    normal_train_data = data.loc[:, normal_train]\n",
    "    cancer_test_data = data.loc[:, cancer_test]\n",
    "    normal_test_data = data.loc[:, normal_test]\n",
    "    return train_data, test_data, test_labels, cancer_train_data, normal_train_data, cancer_test_data,normal_test_data\n",
    "\n",
    "f1score_and_youdenindex = []\n",
    "\n",
    "for i in range(50):\n",
    "    train_data, test_data, test_labels,cancer_train_data, normal_train_data, cancer_test_data,normal_test_data = split_data(r\"D:\\WORKSPACE2\\...\")\n",
    "    #train_data.to_csv('train_data.csv')\n",
    "    test_data_name = str(i)+ '_test_data.csv'\n",
    "    test_data.to_csv(test_data_name)\n",
    "    \n",
    "    test_labels_name = str(i)+ '_labels_data.csv'\n",
    "    test_labels.to_csv(test_labels_name)\n",
    "    \n",
    "    cancer_train_data_name = str(i)+ '_cancer_train_data.csv'\n",
    "    cancer_train_data.to_csv(cancer_train_data_name)\n",
    "    \n",
    "    normal_train_data_name = str(i)+ 'normal_train_data.csv'\n",
    "    normal_train_data.to_csv( normal_train_data_name)\n",
    "    #cancer_test_data.to_csv('cancer_test_data.csv')\n",
    "    #normal_test_data.to_csv('normal_test_data.csv')\n",
    "\n",
    "\n",
    "\n",
    "    wait_for_clust = test_data\n",
    "    wait_for_clust = wait_for_clust.T\n",
    "    wait_for_clust = wait_for_clust.astype('float64')\n",
    "    wait_for_clust\n",
    "\n",
    "\n",
    "    wait_clust_cancer_data = wait_for_clust\n",
    "\n",
    "    csv_path_cancer = cancer_train_data\n",
    "    gaussian_best_dist_df_cancer = gaussian_mixture_distribution(csv_path_cancer,wait_clust_cancer_data,0.5)    \n",
    "    other_best_dist_df_cancer = set_distribution(csv_path_cancer,wait_clust_cancer_data,0.5)\n",
    "    #print(other_best_dist_df)\n",
    "    all_dist_cancer = pd.concat([gaussian_best_dist_df_cancer,other_best_dist_df_cancer],axis=0)\n",
    "    #print(all_dist_cancer)\n",
    "    all_dist_cancer.reset_index(inplace=True, drop=True)\n",
    "    finally_data_cancer = pd.DataFrame(index=['gene', 'Distribution', 'sumsquare_error', 'aic', 'bic', 'ks', 'ks_pvalue','lastresult'])\n",
    "    grouped = all_dist_cancer.groupby('gene')\n",
    "    for name, group in grouped:\n",
    "        result = group.sort_values('bic').iloc[0]\n",
    "        finally_data_cancer = pd.concat([finally_data_cancer,result],axis=1)\n",
    "\n",
    "    finally_data_cancer = finally_data_cancer.T\n",
    "    out_path_cancer = str(i)+'_train_dist_result_cancer.xlsx'\n",
    "    finally_data_cancer.to_excel(out_path_cancer)\n",
    "\n",
    "        \n",
    "                \n",
    "    wait_clust_normal_data = wait_for_clust\n",
    "    csv_path_normal = normal_train_data\n",
    "    gaussian_best_dist_df_normal = gaussian_mixture_distribution(csv_path_normal,wait_clust_normal_data,0.5)\n",
    "    other_best_dist_df_normal = set_distribution(csv_path_normal,wait_clust_normal_data,0.5)\n",
    "    #print(other_best_dist_df)\n",
    "    all_dist_normal = pd.concat([gaussian_best_dist_df_normal,other_best_dist_df_normal],axis=0)\n",
    "    #print(all_dist_normal)\n",
    "    all_dist_normal.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    finally_data_normal = pd.DataFrame(index=['gene', 'Distribution', 'sumsquare_error', 'aic', 'bic', 'ks', 'ks_pvalue','lastresult'])\n",
    "    grouped = all_dist_normal.groupby('gene')\n",
    "    for name, group in grouped:\n",
    "        result = group.sort_values('bic').iloc[0]\n",
    "        finally_data_normal = pd.concat([finally_data_normal,result],axis=1)\n",
    "    finally_data_normal = finally_data_normal.T\n",
    "    out_path_normal = str(i)+'_train_dist_result_normal.xlsx'\n",
    "    finally_data_normal.to_excel(out_path_normal)\n",
    "\n",
    "\n",
    "\n",
    "    finally_data_cancer_filtered = finally_data_cancer[finally_data_cancer['ks_pvalue'] > 0.01]\n",
    "    finally_data_normal_filtered = finally_data_normal[finally_data_normal['ks_pvalue'] > 0.01]\n",
    "    cancer_genes = set(finally_data_cancer_filtered.iloc[:, 0].tolist())\n",
    "    normal_genes = set(finally_data_normal_filtered.iloc[:, 0].tolist())\n",
    "\n",
    "\n",
    "    common_genes = list(cancer_genes & normal_genes)\n",
    "\n",
    "\n",
    "    filtered_cancer_data = finally_data_cancer_filtered[finally_data_cancer_filtered.iloc[:, 0].isin(common_genes)]\n",
    "    filtered_normal_data = finally_data_normal_filtered[finally_data_normal_filtered.iloc[:, 0].isin(common_genes)]\n",
    "\n",
    "    filtered_cancer_data = filtered_cancer_data.set_index(filtered_cancer_data.columns[0])\n",
    "    filtered_normal_data = filtered_normal_data.set_index(filtered_normal_data.columns[0])\n",
    "\n",
    "    posterior_probability_cancer =  filtered_cancer_data['lastresult']\n",
    "    posterior_probability_normal = filtered_normal_data['lastresult']\n",
    "    posterior_probability_cancer = posterior_probability_cancer.apply(lambda x: ','.join(map(str, x))).str.split(',', expand=True)\n",
    "    posterior_probability_normal = posterior_probability_normal.apply(lambda x: ','.join(map(str, x))).str.split(',', expand=True)\n",
    "\n",
    "    row_names = wait_for_clust.index.tolist()\n",
    "\n",
    "\n",
    "    posterior_probability_cancer.columns = row_names\n",
    "\n",
    "    out_path_cancer_posterior = str(i)+'_posterior_probability_cancer.xlsx'\n",
    "    posterior_probability_cancer.to_excel(out_path_cancer_posterior)\n",
    "\n",
    "    posterior_probability_normal.columns = row_names\n",
    "\n",
    "    out_path_normal_posterior = str(i)+'_posterior_probability_normal.xlsx'\n",
    "    posterior_probability_normal.to_excel(out_path_normal_posterior)\n",
    "\n",
    "    column_names = posterior_probability_cancer.columns\n",
    "\n",
    "\n",
    "    sample_type=[]\n",
    "    for col_name in column_names:\n",
    "\n",
    "        \n",
    "        col_cancer = posterior_probability_cancer[col_name].astype('float64')\n",
    "        col_cancer = np.add(col_cancer, 0.000000001)#\n",
    "        multiplied_col_cancer = np.multiply.reduce(col_cancer)*0.5\n",
    "        col_normal = posterior_probability_normal[col_name].astype('float64')\n",
    "        col_normal = np.add(col_normal, 0.000000001)#\n",
    "        multiplied_col_normal = np.multiply.reduce(col_normal)*0.5\n",
    "        greater_than = [multiplied_col_cancer >= multiplied_col_normal]\n",
    "        less_than = [multiplied_col_cancer < multiplied_col_normal]\n",
    "        # 统计两列数字中每列数字比另一列数字大的数量\n",
    "        num_greater_than_2nd_col = sum(greater_than)\n",
    "        num_greater_than_1st_col = sum(less_than)   \n",
    "        wait_clust_data_type = identify_sample(num_greater_than_2nd_col, num_greater_than_1st_col)\n",
    "        sample_type.append((col_name,wait_clust_data_type,num_greater_than_2nd_col,num_greater_than_1st_col))\n",
    "    sample_type_df=pd.DataFrame(sample_type, columns=['sample_name','sample_type','癌症样本基因后验概率比正常样本基因后验概率大的数量','癌症样本基因后验概率比正常样本基因后验概率小的数量'])\n",
    "    sample_type_df_name = str(i)+'_test_sample_type_df.xlsx' \n",
    "    sample_type_df.to_excel(sample_type_df_name)\n",
    "\n",
    "\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from sklearn.metrics import f1_score\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    sample_type_df['sample_type'] = sample_type_df['sample_type'].replace({'cancer': 1, 'normal': 0})\n",
    "    sample_type_df_label = sample_type_df.loc[:,'sample_type']\n",
    "    sample_type_df_label=sample_type_df_label.values\n",
    "    sample_type_df_label\n",
    "    ###Y_TEST\n",
    "    true_sample_type_df_label = test_labels\n",
    "    #true_sample_type_df_label=true_sample_type_df_label.T\n",
    "    true_sample_type_df_label=true_sample_type_df_label.values\n",
    " \n",
    "    f1 = f1_score(true_sample_type_df_label, sample_type_df_label, average='weighted')\n",
    "    print(\"F1 score:\", f1)\n",
    "\n",
    "\n",
    "\n",
    "    cm = confusion_matrix(true_sample_type_df_label, sample_type_df_label)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    youden = tp/(tp+fn) - fp/(fp+tn)\n",
    "    print(\"Youden index:\", youden)\n",
    "    #f1score_and_youdenindex[i]=[f1,youden]\n",
    "    f1score_and_youdenindex .append((f1,youden))\n",
    "f1score_and_youdenindex = pd.DataFrame(f1score_and_youdenindex,columns=['F1_score', 'Youden_Index'])\n",
    "f1score_and_youdenindex_name =  'f1score_and_youdenindex.xlsx'\n",
    "f1score_and_youdenindex.to_excel(f1score_and_youdenindex_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
